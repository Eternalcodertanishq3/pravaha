# PravÄha â€” à¤ªà¥à¤°à¤µà¤¾à¤¹

**A vLLM-inspired LLM inference engine with continuous batching and PagedAttention.**

PravÄha means "flow/stream" in Sanskrit, symbolizing continuous batching and token streaming.

## Features (Phase 1 â€” Baseline)

- âœ… HuggingFace model loading (GPT-2, Llama, Mistral)
- âœ… Configurable dtype (FP16/BF16/FP32)
- âœ… Streaming token generation
- âœ… Sampling pipeline (temperature, top-k, top-p, repetition penalty)
- âœ… GPU memory estimation and monitoring
- âœ… YAML-based configuration

## Roadmap

- âœ… Phase 2: Naive KV-Cache + Streaming Generation
- ğŸ”² Phase 3: Continuous Batching Scheduler
- ğŸ”² Phase 4: Paged KV-Cache + BlockAllocator
- ğŸ”² Phase 5: INT8/INT4 Quantization (GPTQ/AWQ)
- ğŸ”² Phase 6: API Server + Streaming
- ğŸ”² Phase 7: Metrics + Profiler
- ğŸ”² Phase 8: FlashAttention + Speculative Decoding

## Quick Start

```bash
# Install
pip install -e ".[dev]"

# Run
python -c "
from pravaha.engine import PravahaEngine
engine = PravahaEngine()
for token in engine.generate('Once upon a time', max_new_tokens=50, temperature=0.8):
    print(token, end='', flush=True)
print()
"

# Tests
python -m pytest tests/ -v             # Fast tests only
python -m pytest tests/ -v --run-slow  # All tests (downloads models)
```

## Project Structure

```
pravaha/
â”œâ”€â”€ config.py           # Pydantic configuration system
â”œâ”€â”€ engine.py           # Top-level inference orchestrator
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ loader.py       # HuggingFace model loading
â”‚   â”œâ”€â”€ model_config.py # Architecture detection
â”‚   â””â”€â”€ weights.py      # Weight loading utilities
â”œâ”€â”€ tokenizer/
â”‚   â””â”€â”€ tokenizer.py    # HuggingFace tokenizer wrapper
â”œâ”€â”€ decoder/
â”‚   â”œâ”€â”€ decoder.py      # Autoregressive decode loop
â”‚   â””â”€â”€ sampling.py     # Sampling strategies
â”œâ”€â”€ scheduler/
â”‚   â””â”€â”€ request.py      # Request/sequence data structures
â”œâ”€â”€ kv_cache/           # (Phase 2-4)
â”œâ”€â”€ quantization/       # (Phase 5)
â”œâ”€â”€ server/             # (Phase 6)
â””â”€â”€ metrics/            # (Phase 7)
```

## License

MIT
